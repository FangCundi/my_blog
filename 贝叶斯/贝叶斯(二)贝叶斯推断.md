# 二、贝叶斯推断

1. 条件方法：基于后验分布（条件分布）的统计推断方法，只考虑当前的样本和数据，与未出现的数据无关。

2. 经典推断方法由于没有把未知量当做随机变量，所以只能从区间上进行变化，如给定一百个随机区间，这个未知量落在区间内的概率被当做推断条件。而贝叶斯推断可以直接把未知量当做随机变量，其落在某个区间内的概率当做推断条件。

3. 贝叶斯估计：

   1. 最大后验估计$\theta_{MD}$：使后验密度$\pi(\theta|x)$达到最大值的$\theta$
   2. 后验中位数估计$\theta_{Me}$：后验分布的中位数的$\theta$
   3. 后验期望值估计$\theta_E$：后验分布的期望值

4. 贝叶斯估计的误差：针对后验分布$\pi(\theta|X)$，有贝叶斯估计$\widehat{\theta}$，则：

   1. 后验均方差：$MSE(\widehat{\theta}|X)=E^{\theta|X}(\theta-\widehat{\theta})^2$，即对条件分布$\pi(\theta|x)$求期望

   2. 后验标准误：MSE的算数平方根

   3. 后验方差：当$\widehat{\theta}=\widehat{\theta}_E=E(\theta|X)$的时候，MSE=VAR，即为后验方差

   4. 后验标准差：VAR的算术平方根

   5. 后验均方差与后验方差的关系：

      $MSE(\widehat{\theta}|X)=E^{\theta|X}(\theta-\widehat{\theta})^2\\=E^{\theta|X}[(\theta-\widehat{\theta}_E)+(\widehat{\theta}_E-\widehat{\theta})]^2\\=VAR(\theta|X)+(\widehat{\theta}_E-\widehat{\theta})^2$

      当$\widehat{\theta}=\widehat{\theta}_E$时，即选择后验期望估计的时候，可以使后验均方差达到最小，实际中经常用后验均值（后验期望）作为$\theta$的贝叶斯估计值

5. 区间估计：给$\pi(\theta|X)$找一个可信区间，使$P\{\underline{\theta}\le\theta\le\overline{\theta}|X\}\ge1-\alpha$

   此为参数$\theta$的可信度为$1-\alpha$的贝叶斯可信区间

6. 最大后验密度HPD可信区间，要求区间长度越短越好，面对后验密度函数是单峰连续函数可用如下方法：

   1. 给定一个初始概率k
   2. 计算$\pi(\theta|X)=k$得到$\theta_1,\theta_2$，即区间$C(k)=[\theta_1,\theta_2]$
   3. 计算$P(\theta\in C(k)|X)=\int_{C(k)}\pi(\theta|X)d\theta$
   4. 当$P=1-\alpha$时，表示已经找到区间，结束；否则调整k，转入2

7. 假设检验：获得后验分布$\pi(\theta|X)$之后，计算两个假设$H_0,H_1$的后验概率，比较哪个大即可无需选择检验统计量，无需确定抽样分布，无需事先给出显著性水平，无需确定拒绝域

8. 贝叶斯因子：

   $B^{\pi}(X)=\frac{后验机会比}{先验机会比}=\frac{a_0/a_1}{\pi_0/\pi_1}=\frac{a_0\pi_1}{a_1\pi_0}$

   1. 贝叶斯因子表示数据x支持原假设的程度

   2. 分子表示数据x（$a_0,a_1$）和先验支持假设的程度，分母表示先验支持假设的程度，两者相除就排除了先验分布的干扰

   3. 简单假设对简单假设：$H_0=\{\theta_0\},H_1=\{\theta_1\}$

      此时先验概率是已知的$\pi(\theta_0),\pi(\theta_1)$，而x的条件概率也已知$p(x|\theta_0),p(x|\theta_1)$，故直接带入即可，最终得到的贝叶斯因子是$B^{\pi}(X)=\frac{p(X|\theta_0)}{p(X|\theta_1)}$

   4. 复杂假设对复杂假设：$H_0=\{\theta\in\Theta_0\},H_1=\{\theta\in\Theta_1\}$

      此时先验概率是在一个区间上的积分，后验概率也是如此，直接带入求积分即可。最终得到的贝叶斯因子是$B^{\pi}(X)=\frac{\int_{\Theta_0}p(X|\theta)g_0(\theta)d\theta}{\int_{\Theta_1}p(X|\theta)g_1(\theta)d\theta}=\frac{m_0(X)}{m_1(X)}$

      其中$g_0,g_1$是$\Theta_0,\Theta_1$上的概率密度函数

      这是$\Theta_0,\Theta_1$上的加权似然比

   5. 简单假设对复杂假设：$H_0:\theta=\theta_0,H_1:\theta\neq\theta_0$

      这种情况下不能用连续密度函数作为先验分布，因为求积分的话点积分为0，故需要人为给一个概率$\pi_0$，此时$\pi(\theta)=\pi_0g_0(\theta)+(1-\pi_0)g_1(\theta)$，其中$g_0$是$\theta=\theta_0$的示性函数，$g_1$是正常密度函数。

      这个时候$\pi_0$可以看做实际假设$H_0:\theta\in[\theta_0-\epsilon,\theta_0+\epsilon]$上的先验概率

      此时贝叶斯因子是$B^{\pi}(X)=\frac{p(X|\theta_0)}{m_1(X)}$

      此时后验概率$\alpha_0=[1+\frac{1-\pi_0}{\pi_0}\frac1{B^{\pi}(X)}]^{-1}$

9. 预测：对未来观察值（随机变量）做出统计推断

   1. 对随机变量X，在参数$\theta$未知的情况下做出X的推测

      这个时候可以利用先验分布$\pi(\theta)$获得x的边缘分布，并用边缘分布的期望、中位数或者众数作为预测，也可以获得确定性一定的预测区间

      $m(x)=\int_{\Theta}p(x|\theta)\pi(\theta)d\theta$

   2. 在有X的样本的情况下，在参数$\theta$未知的情况下做出X的推测

      这个时候可以利用后验分布$\pi(\theta|X)$获得x的边缘分布

      $m(x|X)=\int_{\Theta}p(x|\theta)\pi(\theta|X)d\theta$

   3. 在有X的样本的情况下，在参数$\theta$未知的情况下对随机变量Z做出推测，随机变量X和随机变量Z具有相同的未知参数$\theta$

      这个时候直接用X的样本去计算未知参数$\theta$的后验分布，并带入到z的边缘分布

      $m(z|X)=\int_{\Theta}p(z|\theta)\pi(\theta|X)d\theta$

10. 似然原理：

    1. 若设$X=\{x_1,...,x_n\}$是来自密度函数$p(x|\theta)$的一个样本，则其乘积为：

       $p(X|\theta)=\prod_{i=1}^np(x_i|\theta)$

       1. 当$\theta$给定的时候，$p(x|\theta)$是样本X的联合密度函数
       2. 当X的观测值给定的时候，$p(x|\theta)$是未知参数$\theta$的函数，即似然函数$L(\theta)$

    2. 有了观察值x之后，在做关于$\theta$的推断和决策时，所有与试验有关的$\theta$信息均被包含在似然函数L($\theta$)之中。

    3. 如果有两个似然函数是成比例的，比例常数与$\theta$无关，则他们关于$\theta$含有相同的信息。

11. 例题

    1. 设$x_1,..,x_n$是来自正态总体$N(\theta,\sigma^2)$的一个样本，其中$\sigma^2$已知，若取$\theta$的共轭先验分布$N(\mu,\gamma^2)$作为的先验分布，其中$\mu$与$\gamma^2$已知，求$\theta$的Bayes估计。

       首先计算$\theta$的后验分布，由于正态均值的共轭先验分布是正态分布，所以$\theta$的后验分布易得为$N(\mu_1,\gamma_1^2)$

       正态分布的贝叶斯估计三点重合，都是正态均值

       所以$\theta$的贝叶斯估计是$\widehat{\theta}_B=\mu_1=\frac{\gamma^{-2}}{\sigma^{-2}/n+\gamma^{-2}}\mu+\frac{\sigma^{-2}/n}{\sigma^{-2}/n+\gamma^{-2}}\overline{x}=\frac{\sigma^2\mu/n+\gamma^2/\overline{x}}{\sigma^2/n+\gamma^2}$

    2. 为估计不合格率$\theta$，从一批产品中随机抽取n件，其中不合格品数X服从$B(n,p)$，一般选取$Be(\alpha,\beta)$为$\theta$的先验分布，设$\alpha,\beta$已知，求$\theta$的贝叶斯估计

       首先求$\theta$的后验分布，由于二项分布的合格率的共轭先验分布就是贝塔分布，所以可以轻松根据共轭先验得到$\theta$的后验分布是$Be(\alpha+x,\beta+n-x)$

       根据后验分布可以算得贝叶斯估计：

       $\widehat{\theta}_{MD}=\frac{\alpha+x-1}{\alpha+\beta+n-2},\widehat{\theta}_E=\frac{\alpha+x}{\alpha+\beta+n}$

    3. 假设x是来自指数分布的一个观察值（样本），$p(x|\theta)=e^{-(x-\theta)},x\ge\theta$，又取柯西分布作为$\theta$的先验分布，即$\pi(\theta)=\frac1{\pi(1+\theta^2)}$，求$\theta$的最大后验估计

       根据先验分布和样本分布可以得到后验分布

       由于x是只有一个样本，所以$p(x|\theta)=p(x|\theta)=e^{-(x-\theta)}$

       所以联合分布函数为$h(x,\theta)=p(x|\theta)\pi(\theta)=\frac{e^{-(x-\theta)}}{\pi(1+\theta^2)}$

       对$\theta$求积分可以得到x的边缘分布$m(x)$

       两者相除可以得到$\theta$的后验分布$\pi(\theta|x)=\frac{e^{-(x-\theta)}}{m(x)\pi(1+\theta^2)}$

       对后验分布关于$\theta$求导，导数为零的时候就是后验分布最大的情况

       $\frac d{d\theta}\pi(\theta|x)=\frac{e^{-x}}{m(x)\pi}[\frac{e^{\theta}}{1+\theta^2}-\frac{2\theta e^{\theta}}{(1+\theta^2)^2}]=\frac{e^{-x}e^{\theta}(\theta-1)^2}{m(x)(1+\theta^2)^2\pi}$

       可以看到，由于各项均是恒大于0的（包括m(x)，概率不能小于0），所以导数恒大于0

       所以，后验分布整体是递增的，随着$\theta$的增大，后验分布概率越大，而$\theta$存在上限x，所以$\widehat{\theta}_{MD}=x$

    4. 假设X是来自指数分布的多个观察值（样本集），$p(X|\theta)=e^{-(x-\theta)},X\ge\theta$，又取柯西分布作为$\theta$的先验分布，即$\pi(\theta)=\frac1{\pi(1+\theta^2)}$，求$\theta$的最大后验估计

       根据先验分布和样本分布可以得到后验分布

       由于x是只有一个样本，所以$p(X|\theta)=\prod_{i=1}^n p(x_i|\theta)=e^{-\sum_{i=1}^n (x_i-\theta)}$

       所以联合分布函数为$h(x,\theta)=p(x|\theta)\pi(\theta)=\frac{e^{-\sum_{i=1}^n(x_i-\theta)}}{\pi(1+\theta^2)}$

       对$\theta$求积分可以得到x的边缘分布$m(x)$

       两者相除可以得到$\theta$的后验分布$\pi(\theta|x)=\frac{e^{-\sum_{i=1}^n(x_i-\theta)}}{m(x)\pi(1+\theta^2)}$

       对后验分布关于$\theta$求导，导数为零的时候就是后验分布最大的情况

       $\frac d{d\theta}\pi(\theta|x)=\frac{e^{-\sum_{i=1}^n x_i}}{m(x)\pi}[\frac{ne^{n\theta}}{1+\theta^2}-\frac{2n\theta e^{n\theta}}{(1+\theta^2)^2}]=\frac{e^{-\sum_{i=1}^n x}ne^{n\theta}(\theta-1)^2}{m(x)(1+\theta^2)^2\pi}$

       可以看到，由于各项均是恒大于0的（包括m(x)，概率不能小于0），所以导数恒大于0

       所以，后验分布整体是递增的，随着$\theta$的增大，后验分布概率越大，而$\theta$存在上限$\min_{i=1}^n(x_i)$，所以$\widehat{\theta}_{MD}=\min_{i=1}^n(x_i)$

    5. 设一批产品的不合格率为$\theta$，检查是一个一个进行，直到发现第一个不合格产品为止，若X为发现第一个不合格品时已经发现的产品数，则X服从几何分布：

       $p(X=x|\theta)=\theta(1-\theta)^{x-1},x=1,2...$

       设$\theta$的先验分布为$p(\theta=\frac i4)=\frac13,i=1,2,3$，如今只获得一个样本观察值x=3，求$\theta$的最大后验估计，后验期望估计，并计算误差

       此为典型的离散形式的贝叶斯公式使用案例。

       首先求联合分布$h(x,\theta)=p(x=3|\theta)\pi(\theta)=\frac i4(1-\frac i4)^2\frac13$

       在对联合分布函数求和得到x的边缘分布$m(x)=\sum_{i=1,2,3}p(x=3|\theta)\pi(\theta)=\\\frac13\frac14(1-\frac14)^2+\frac13\frac24(1-\frac24)^2+\frac13\frac34(1-\frac34)^2=\frac5{48}$

       再求后验分布为$\pi(\theta|x=3)=\frac{4i}5(1-\frac i4)^2,i=1,2,3$

       此时求最大后验估计即可求得：$\widehat{\theta}_{MD}=\frac14$

       求后验期望估计为：$\widehat{\theta}_E=\sum_{i=1,2,3}\theta p(\theta)=\frac{17}{40}$

       计算误差就是计算后验均方差

       对后验期望估计有：$MSE(\widehat{\theta}_E)=E^{\theta|x}(\theta-\widehat{\theta}_E)\\=(\frac14-\frac{17}{40})^2\frac9{20}+(\frac24-\frac{17}{40})^2\frac8{20}+(\frac34-\frac{17}{40})^2\frac3{20}=51/1600$

       对最大后验估计有：

       $MSE(\widehat{\theta}_{MD})=E^{\theta|x}(\theta-\widehat{\theta}_{MD})\\=(\frac14-\frac{1}{4})^2\frac9{20}+(\frac24-\frac{1}{4})^2\frac8{20}+(\frac34-\frac{1}{4})^2\frac3{20}=1/16$

    6. 设$x_1,...,x_n$是来自正态总体$N(\theta,\sigma^2)$的一个样本观察集，其中$\sigma^2$已知，若正态均值的先验分布选取为$N(\mu,\gamma^2)$，其中$\mu,\gamma$已知，求$\theta$的$1-\alpha$可信区间

       由于正态均值的共轭先验分布是正态分布，所以设为$N(\mu_1,\gamma^2_1)$

       由于正态分布的对称性，所以只需要求$p(\theta_1\le\theta\le\theta_2)=1-\alpha$

       可有$\theta_1=\mu_1-\sigma_1\mu_{1-\alpha/2},\theta_2=\mu_1+\sigma_1\mu_{1-\alpha/2}$

       其中$\mu_{1-\alpha/2}$是标准正态分布的$1-\alpha/2$分位点

    7. 为了研究我国某弹药平均寿命的贝叶斯估计，经过早期筛选后，弹药的寿命服从指数分布，它的密度函数为：$p(t|\theta)=\theta^{-1}e^{-t/\theta},t>0$，其中$\theta>0$是弹药的平均寿命。现从一批弹药中随机抽取n台进行寿命试验，试验到第r(r≤n)个失效为止，其失效时间为$t_1\le t_2\le...\le t_r$另外n-r个弹药直到试验停止时还未失效，此为**截尾寿命试验**，所得样本T=$(t_1,...,t_r)$称为截尾样本，此结尾样本的联合密度函数为：

       $p(T|\theta)\varpropto[\prod_{i=1}^rp(t_i|\theta)][1-F(t_r)]^{n-r}=\theta^{-r}exp{-s_r/\theta}$

       其中$F(t)$为弹药的寿命的分布函数，$s_r=t_1+...+t_r+(n-r)t_r$称为总实验时间

    8. 设x是从二项分布$b(n,\theta)$中抽取的一个样本，现在考虑两个假设：$\Theta_0={\theta:\theta\le1/2},\Theta_1={\theta:\theta>1/2}$，若取均匀分布$U(0,1)$作为$\theta$的先验分布，做假设检验

       首先求$\theta$的后验分布：$\pi(\theta|x)=\frac{\Gamma(n+2)}{\Gamma(x+1)\Gamma(n-x+1)}\int_0^{1/2}\theta^x(1-\theta)^{n-x}d\theta\\=\frac{\Gamma(n+2)}{\Gamma(x+1)\Gamma(n-x+1)}\frac{(1/2)^{n+1}}{x+1}[1+\frac{n-x}{x+2}+\frac{(n-x)(n-x-1)}{x+2}(x+3)+...+\frac{(n-x)!x!}{(n+1)!}]$

       以此求后验机会比：

       | x                   | 0     | 1     | 2     | 3     | 4     | 5     |
       | ------------------- | ----- | ----- | ----- | ----- | ----- | ----- |
       | $\alpha_0$          | 63/64 | 57/64 | 42/64 | 22/64 | 7/64  | 1/64  |
       | $\alpha_1$          | 1/64  | 7/64  | 22/64 | 42/64 | 57/64 | 63/64 |
       | $\alpha_0/\alpha_1$ | 63.0  | 8.14  | 1.91  | 0.52  | 0.12  | 0.016 |

       从表中可以看出，当$x=0,1,2$时，应接受$\Theta_0$，其余不接受

    9. 设X~N(θ,1)，其中θ只有两种可能，非0即1，需要检验的假设是： H0：θ=0，H1：θ=1。若从该总体中抽取一个容量为n的样本x, 试计算贝叶斯因子及作出相应的决策。

       简单假设情况下的贝叶斯因子只与似然函数有关：

       $\theta=0,p(\overline{x}|0)=\sqrt{\frac{n}{2\pi}}exp\{-\frac{n}2\overline x^2\}$

       $\theta=1,p(\overline{x}|1)=\sqrt{\frac{n}{2\pi}}exp\{-\frac{n}2(\overline{x}-1)^2\}$

       此时可有贝叶斯因子

       $B^{\pi}(x)=exp\{-\frac n2(2\overline{x}-1)\}$

    10. 设从正态总体N(θ,1)中随机抽取一个容量为10的样本x，算得样本均值  =1.5，试对如下两个假设进行检验：H0：θ≤1，H1：θ>1。取θ的共轭先验分布为N(0.5,2)。 

        根据共轭先验可以得到$\theta$的后验分布$N(1.4523,0.3086^2)$

        根据后验分布来计算两个区间的后验概率

        $\alpha_0=\pi(\theta\le1|x)=\int_{-\infty}^1{\frac1{\sqrt{2\pi}0.3086}exp\{-\frac{(\theta-1.4523)^2}{2*0.3086^2}\}}d\theta=0.0708$

        $\alpha_1=\pi(\theta\ge1|x)=\int_{-1}^{\infty}{\frac1{\sqrt{2\pi}0.3086}exp\{-\frac{(\theta-1.4523)^2}{2*0.3086^2}\}}d\theta=0.9292$

        此时计算后验机会比为$\alpha_0/\alpha_1=0.0761$，这个值小于1，所以接收$H_1$。

        同理，可以求得先验概率

        $\pi_0=\int_{-\infty}^1{\frac1{\sqrt{2\pi}2}exp\{-\frac{(\theta-0.5)^2}{2*2}\}}d\theta=0.6368$

        $\pi_1=\int_{1}^{\infty}{\frac1{\sqrt{2\pi}2}exp\{-\frac{(\theta-0.5)^2}{2*2}\}}d\theta=0.3632$

        有先验机会比为$\pi_0/\pi_1=1.7533$，可以看到先验支持$H_0$

        两者做比可以得到贝叶斯因子：$B^{\pi}(x)=0.0761/1.7533=0.0434$

        可以看到数据支持$H_1$

    11. 设x是从二项分布b(n, θ)中抽取的一个样本，现考察如下两个假设 H0:θ=1/2  , H1:θ≠1/2。若设在θ≠1/2上的密度g1(θ)为区间(0,1)上的均匀分布U(0,1)，试做出恰当的判断。

        有$\theta$的先验分布为$\pi(\theta)=\begin{cases}1,0<\theta<1\\0,other\end{cases}$

        有x的分布函数为$p(x|\theta)=C_n^x\theta^x(1-\theta)^{n-x}$

        有联合分布函数$h(x,\theta)=C_n^x\theta^x(1-\theta)^{n-x}$

        有x的边缘分布$m(x)=\int_0^1C_n^x\theta^x(1-\theta)^{n-x}d\theta\\=C_n^x\frac{\Gamma(x+1)\Gamma(n-x+1)}{\Gamma(n+2)}$

        于是有贝叶斯因子为$B^{\pi}(x)=\frac{p(x|\theta_0)}{m_1(x)}\\=\frac{C_n^x\theta_0^x(1-\theta_0)^{n-x}}{C_n^x\frac{\Gamma(x+1)\Gamma(n-x+1)}{\Gamma(n+2)}}\\=\frac{(\frac12)^x(\frac12)^{n-x}\Gamma(n+2)}{\Gamma(x+1)\Gamma(n-x+1)}\\=\frac{(\frac12)^n(n+1)!}{x!(n-x)!}$

        此时也可以计算出$H_0:\theta=1/2$的后验概率

        $\pi(\theta_0|x)=[1+\frac{1-\pi_0}{\pi_0}\frac1{B^{\pi}(x)}]^{-1}=[1+\frac{1-\pi_0}{\pi_0}\frac{2^nx!(n-x)!}{(n+1)!}]$

    12. Berger(1995)一个临床试验有两个处理：

        处理1：服药A；

        处理2：同时服药A与药B。

        如今进行n次对照试验，设xi为第i次对照试验中处理2与处理1的疗效之差，又设诸xi相互独立同分布，且都服从N(θ,1)，于是前n次的样本均值 $\overline{x}_n-N(\theta,1/n)$ ，先要考察如下二个假设：H0：θ=0   H1：θ≠0
        由于对二个处理的疗效知之甚少，故对H0和H1取相等概率，即π0=π1=1/2，而对H1：θ≠0上的先验密度g1(θ)一般看法是：参数θ（疗效之差）接近于0比远离0更为可能，故取正态分布N(0,2)作为g1(θ)

        问题：这两种处理方式有没有差别？如果有差别，哪一种方式的疗效更好？

        首先有样本均值的分布$\overline{x}-N(\theta,1/n),\\p(\overline{x}_n|\theta)=\sqrt{\frac n{2\pi}}exp\{-\frac n2(\overline{x}_n-\theta)^2\}$

        $\theta$的先验分布是$\theta-N(0,2),\\g_1(\theta)=\frac1{2\sqrt{\pi}}exp\{-\frac{\theta^2}4\}$

        $\overline{x}_n$的边缘分布是：

        $m_1(\overline{x}_n)=\int_{-\infty}^{\infty}p(\overline x|\theta)g_1(\theta)d\theta\\=\frac1{2\pi}\sqrt{\frac n2}\int_{-\infty}^{\infty}exp\{-\frac12[n(\overline{x}_n-\theta)^2+\frac{\theta^2}2]\}d\theta\\=\frac1{\sqrt{2\pi}}\frac{1}{\sqrt{2+\frac1n}}exp\{-\frac{\overline{x}_n}2/(2+\frac1n)\}$

        由此可知，$\theta$的后验分布为

        $\pi(\theta|\overline{x}_n)=p(\overline x_n|\theta)g_1(\theta)/m_1(\overline x_n)\\=\sqrt{\frac n{2\pi}}\frac1{2\sqrt{\pi}}exp\{-\frac{n}2(\overline x_n-\theta)^2-\frac{\theta^2}4\}/(\frac1{\sqrt{2\pi}}\frac1{\sqrt{2+\frac1n}}exp\{-\frac{\overline x_n}2/(2+\frac1n)\})\\=\frac1{\sqrt{2\pi}}\sqrt{n+\frac12}exp\{-\frac12(n+\frac12)(\theta-\frac{n\overline x_n^2}{n+\frac12})^2\}$

        此为正态分布（不包含$\theta=0$）：$N(n\overline x_n/(n+\frac12),(n+\frac12)^{-1})$

        可有贝叶斯因子为：

        $B^{\pi}(\overline x_n)=\frac{p(\overline x_n|\theta=0)}{m_1(\overline x_n)}=\frac{\sqrt{\frac n{2\pi}}exp{-n\overline x_n^2/2}}{\frac1{\sqrt{2\pi}}\sqrt{\frac n{1+2n}}exp\{-\frac{\overline x_n^2}2/(2+\frac1n)\}}\\=\sqrt{1+2n}exp\{-\frac{n\overline x_n^2}2/(1+\frac1{2n})\}$

        根据贝叶斯因子可以求得后验概率

        $\alpha_0=p(\theta=0|\overline x_n)=(1+\frac1{B^{\pi}(\overline x_n)})^{-1}=\frac{B^{\pi}(\overline x_n)}{1+B^{\pi}(\overline x_n)}$

        $\alpha_1=p(\theta\ne0|\overline x_n)=\frac1{1+B^{\pi}(\overline x_n)}$

        可以看到根据贝叶斯因子是否大于1可以进行判定接收哪一个

        当考虑哪种更好的时候，需要设立三个假设：

        $H_0:\theta=0,H_1:\theta<0,H_2:\theta>0$

        同理，可以利用上面求得的$\theta\ne0$时候的后验分布$N(n\overline x_n/(n+\frac12),(n+\frac12)^{-1})$

        可以直接算出两个假设的后验概率，求积分即可

        $\alpha_1=p(\theta<0|\overline x_n)=\Phi(\frac{-\sqrt n\overline x_n}{\sqrt{1+\frac1{2n}}})/(1+B^{\pi}(\overline x_n))$

        $\alpha_2=p(\theta>0|\overline x_n)=\Phi(\frac{\sqrt n\overline x_n}{\sqrt{1+\frac1{2n}}})/(1+B^{\pi}(\overline x_n))$

    13. 在n次相互独立的贝努里实验成功了x次，试对未来k次相互独立的贝努里实验中的成功次数z做出预测

        假设成功的概率为$\theta$，则原始的实验是一个二项分布$b(n,\theta)$

        $p(x|\theta)=C_n^x\theta^x(1-\theta)^{n-x}$

        现在需要根据样本来计算$\theta$的后验分布

        首先假设$\theta$的先验分布是共轭先验分布，即贝塔分布$Be(\alpha,\beta)$

        那么就有后验分布为贝塔分布$Be(x+\alpha-1,n-x+\beta-1)$

        $\pi(\theta|x)=\frac{\Gamma(n+\alpha+\beta)}{\Gamma(x+\alpha)\Gamma(n-x+\beta)}\theta^{x+\alpha-1}(1-\theta)^{n-x+\beta-1}$

        有了后验分布之后就可以得到新样本的似然函数

        $p(z|\theta)=C_k^z\theta^z(1-\theta)^{k-z}$

        在这个里面，$\theta$就是x中的$\theta$，相当于两个分布共用同一个参数

        此时就可以根据似然定理进行预测$\pi(z|x)=\int_{\Theta}p(z|\theta)\pi(\theta|x)d\theta=\int_0^1p(z|\theta)\pi(\theta|x)d\theta\\=\int_0^1C_k^z\theta^z(1-\theta)^{k-z}\frac{\Gamma(n+\alpha+\beta)}{\Gamma(x+\alpha)\Gamma(n-x+\beta)}\theta^{x+\alpha-1}(1-\theta)^{n-x+\beta-1}d\theta\\=C_k^z\frac{\Gamma(n+\alpha+\beta)}{\Gamma(x+\alpha)\Gamma(n-x+\beta)}\int_0^1\theta^{z+x+\alpha-1}(1-\theta)^{k-z+n-x+\beta-1}d\theta\\=C_k^z\frac{\Gamma(n+\alpha+\beta)\Gamma(z+x+\alpha)\Gamma(k-z+n-x+\beta)}{\Gamma(x+\alpha)\Gamma(n-x+\beta)\Gamma(n+k+\alpha+beta)}$

        这里可以理解为，在扔骰子的时候，一般应该假设骰子是绝对均匀的，扔出来的每个面的概率一定。但现实中，由于做工问题，可能会导致某个面的概率与其他不同，这个时候根据先验，就可以预测后续的情况